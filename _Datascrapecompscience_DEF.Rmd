# Webscraping the staff of the Instititute for Computing and Information Science

<br>

# Packages

```{r}
#start with clean workspace 
rm(list=ls())

# install.packages("data.table") 
library(data.table) # mainly for faster data handling
library(tidyverse) # I assume you already installed this one!
# install.packages("httr") # we don't need this for now
# require(httr)
# install.packages("xml2")
require(xml2)
# install.packages("rvest")
require(rvest)
# install.packages("devtools")
require(devtools)
# Note we're doing something different here. We're installing a *latest* version directly from GitHub
# This is because the released version of this packages contains some errors!
#devtools::install_github("jkeirstead/scholar") 


require(scholar)

#define workdirectory, note the double *backslashes* if you're on windows
# setwd("/yourpathhere)"
```

<br>

# Save webpage with staff names 
```{r}
# Getting the staff page by the function read_html to extract html webpages and put them in xml format

comp_staff <- read_html("https://www.cs.ru.nl/staff/index.html?")


```

<br>

# from xml to nice df of names

## selecting the table with names
```{r}
# Individual scholars are mentioned at "a" elements of the html
comp_staff <- comp_staff %>%
    rvest::html_nodes("body") %>%
    xml2::xml_find_all("//a") %>% # Bas --> notice this change, if you inspect the page, you see that individual scholars are mentioned at "a" elements of the html
    rvest::html_text()
comp_staff

```


## Making a dataframe of comp_staff, called comp_df
```{r}
comp_df <- data.frame(comp_staff)

print(comp_df)
```
<br>

# Cleaning the dataset  

## Removing all individual letters of the alphabet

```{r}
delrows <- which(comp_df$comp_staff == "A" | comp_df$comp_staff == "B" | comp_df$comp_staff == "C" | comp_df$comp_staff == "D" | comp_df$comp_staff == "E" | comp_df$comp_staff == "F" |  comp_df$comp_staff == "G" | comp_df$comp_staff == "H" | comp_df$comp_staff == "I" | comp_df$comp_staff == "J" | comp_df$comp_staff == "K" | comp_df$comp_staff == "L" | comp_df$comp_staff == "M" | comp_df$comp_staff == "N" | comp_df$comp_staff == "O" | comp_df$comp_staff == "P" | comp_df$comp_staff == "Q" | comp_df$comp_staff == "R" | comp_df$comp_staff == "S" | comp_df$comp_staff == "T" | comp_df$comp_staff == "U" | comp_df$comp_staff == "V" | comp_df$comp_staff == "W" | comp_df$comp_staff == "X" | comp_df$comp_staff == "Y" | comp_df$comp_staff == "Z")

comp_df <- comp_df[-delrows, ]
```


## Creating a dataframe of comp_df, called compsc_df

```{r}
compsc_df <- data.frame(comp_df)

# Giving the first (and only column) of comp_df the name 'comp_names'
colnames(compsc_df)[colnames(compsc_df) == "comp_df"] <- "comp_names"

colnames(compsc_df)

save(compsc_df, file="compsc_df.RData")
```

## Cleaning the names a bit  

```{r}
# Creating a new variable with the titles of the respondents
compsc_df$title <- gsub(" .*", "", compsc_df$comp_names)

# Creating a new variable with the last names of the respondents
compsc_df$last_name <- gsub('^.* ([[:alnum:]]+)$', '\\1', compsc_df$comp_names)

# Creating a new variable with the first names of the respondents
compsc_df$first_name <- str_extract_all(compsc_df$comp_names, "(?<=\\().+?(?=\\))", simplify = TRUE)
```

```{r}
# trimws looses all spacing before and after (if you specify 'both') a character string
compsc_df$last_name <- trimws(compsc_df$last_name, which = c("both"), whitespace = "[ \t\r\n]")
compsc_df$first_name <- trimws(compsc_df$first_name, which = c("both"), whitespace = "[ \t\r\n]")
compsc_df$comp_names <- trimws(soc_df$soc_names, which = c("both"), whitespace = "[ \t\r\n]")

compsc_df$first_name <- as.character(str_split(compsc_df$first_name, pattern=" ", n = 2, simplify = TRUE)[,1])
compsc_df$first_name <- as.character(str_split(compsc_df$first_name, pattern="-", n = 2, simplify = TRUE)[,1])
```

```{r}
#removing strange characters
compsc_df$first_name <- iconv(compsc_df$first_name, from = 'UTF-8', to = 'ASCII//TRANSLIT')
compsc_df$last_name <- iconv(compsc_df$last_name, from = 'UTF-8', to = 'ASCII//TRANSLIT')
```


## Removing mistakes in the cleaning of the names

```{r}
compsc_df$last_name[compsc_df$last_name == 'bibihayat'] <- 'akbari bibihayat'

compsc_df$last_name[compsc_df$last_name == 'eliasi'] <- 'amiri eliasi'

compsc_df$last_name[compsc_df$last_name == 'hirch'] <- 'el hirch'

compsc_df$last_name[compsc_df$last_name == 'msc d.m. (dennis) groa?'] <- 'gross'

compsc_df$first_name[compsc_df$first_name == 'dania<l'] <- 'daniel'

compsc_df$last_name[compsc_df$last_name == 'jeshveghani'] <- 'moti jeshveghani'

compsc_df$last_name[compsc_df$last_name == 'schip'] <- 'van t Schip'

compsc_df$first_name[compsc_df$first_name == 'sven'] <- 'sven-bodo'

compsc_df$first_name[compsc_df$first_name == 'maria<lle'] <- 'marielle'

compsc_df$last_name[compsc_df$last_name == 'vegt'] <- 'van der vegt'

compsc_df$last_name[compsc_df$last_name == 'weide'] <- 'van der Weide'

compsc_df$last_name[compsc_df$last_name == 'wetering'] <- 'van de wetering'

compsc_df$last_name[compsc_df$last_name == 'schreur'] <- 'wichers schreur'

compsc_df$last_name[compsc_df$last_name == 'dr. t.t. (thorsten) wia?mann'] <- 'wismann'

compsc_df$last_name[compsc_df$last_name == 'borgesius'] <- 'zuiderveen borgesius'

```


## Turning all letters into lowercase letters

```{r}
compsc_df$first_name <- tolower(compsc_df$first_name)  
compsc_df$last_name <- tolower(compsc_df$last_name)
```

```{r}
# Saving the final dataset
save(compsc_df, file="compsc_df.RData")
```

<br>

# Adding gender to dataset

## fgender

```{r}
# install.packages('polite')
```


```{r}
fgender <- function(firstname_df, me, file=NULL) {

####################################
# Author: Bas Hofstra, Anne Maaike Mulders, Jochem Tolsma
# DAte:   13-10-2021, last edit: 22-09-2022
# Tasks:  - assign gender baed on name
#         - Adapted from Rense Corten code April 2021
####################################


#Input: 
#  - firstname_df: a data.frame with a column named firstname  
#  - me: a character vector introducing yourself: e.g. "J Tolsma, Radboud University"
#  - file: location and name of file to be saved. 
  
#------------------------------------------------------------------------------------
# Load required packages

if (!require("tidyverse", character.only = TRUE)) {
  install.packages("tidyverse", dependencies = TRUE)
  library(tidyverse, character.only = TRUE)
}

if (!require("rvest", character.only = TRUE)) {
  install.packages("rvest", dependencies = TRUE)
  library(rvest, character.only = TRUE)
}

if (!require("polite", character.only = TRUE)) {
  install.packages("polite", dependencies = TRUE)
  library(polite, character.only = TRUE)
}



# make links to scrape
firstname_df$name_url <- paste0("https://www.meertens.knaw.nl/nvb/naam/is/", firstname_df[, c("firstname")])



#------------------------------------------------------------------------------------
### 2: introduce to server ###

# Introduce myself to the server
session <- bow("https://www.meertens.knaw.nl/nvb/naam/is", user_agent = me , delay = 1)


#------------------------------------------------------------------------------------
### 3: make function to get table from ###
  fnames <- function(link){ 
    name_session <-nod(session, path = link)
    name_page <- scrape(name_session) 
    return(name_page)
  }
  
name_list <- list()
table_list <- list()
firstname_df$gender <- NA

  for (i in 1:nrow(firstname_df)) {
    print(i)
    name_list[[i]] <- fnames(firstname_df[i, c("name_url")])
    # extract name frequency table and gender info
    table_list[[i]] <- name_list[[i]] %>% html_table()
    
    table_list[[i]][[1]][table_list[[i]][[1]]=="--"] <- "0"
    
    if (as.numeric(table_list[[i]][[1]]$X3[2]) > as.numeric(table_list[[i]][[1]]$X3[6])) {
      firstname_df$gender[i] <- "male" } else {
        firstname_df$gender[i] <- "female"
      }
    
    if (!is.null(file)) (save(firstname_df, file=file))
    
    }
  return(firstname_df)
}
```

## gender to soc_df
```{r}
compsc_df %>% mutate(firstname=first_name) -> compsc_df

compsc_df$firstname
compsc_df <- fgender(compsc_df, me="Jochem Tolsma, RU/RUG")
```

```{r}
save(compsc_df, file="compsc_df_s1.RData")
```


<br>

# Adding some other data manually


```{r}
# setting an affiliation to Radboud University
compsc_df$affiliation <- "radboud university"
```









```{r}
compsc_df
```

```{r}
# Setting an empty identifier
compsc_df$gs_id <- ""  
```

```{r}
#require(scholar)

get_scholar_id_fix <- function (last_name = "", first_name = "", affiliation = NA)
{
  if (!any(nzchar(c(first_name, last_name))))
    stop("At least one of first and last name must be specified!")
  site <- getOption("scholar_site")
  url <- paste0(site, "/citations?view_op=search_authors&mauthors=",
                first_name, "+", last_name, "&hl=en&oi=ao")
  page <- get_scholar_resp(url)
  if (is.null(page))
    return(NA)
  aa <- httr::content(page, as = "text")
  # added by Bas Hofstra: bugfix for IDs that have a dash ("-")
  ids <- substring(aa, regexpr(";user=", aa))
  ids <- substr(ids, 1, 19) # error prone, but unsure how to solve otherwise
  # if (nchar(stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]")[[1]][1]) < 18) {
  #   ids <- stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]+[[:alnum:]]+[[:punct:]]")
  # } else {
  #   ids <- stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]")
  # }
  if (length(unlist(ids)) == 0) {
    message("No Scholar ID found.")
    return(NA)
  }
  ids <- ids %>% unlist %>% gsub(";user=|[[:punct:]]$", "",
                                 .) %>% unique
  if (length(ids) > 1) {
    profiles <- lapply(ids, scholar::get_profile)
    if (is.na(affiliation)) {
      x_profile <- profiles[[1]]
      warning("Selecting first out of ", length(profiles),
              " candidate matches.")
    }
    else {
      which_profile <- sapply(profiles, function(x) {
        stringr::str_count(string = x$affiliation, pattern = stringr::coll(affiliation,
                                                                           ignore_case = TRUE))
      })
      if (all(which_profile == 0)) {
        warning("No researcher found at the indicated affiliation.")
        return(NA)
      }
      else {
        x_profile <- profiles[[which(which_profile !=
                                       0)]]
      }
    }
  }
  else {
    x_profile <- scholar::get_profile(id = ids)
  }
  return(x_profile$id)
}
```




```{r}
# Getting the google scholar id of all the computing science staff members (by using the following variables: last_name, first_name, affiliation). The gathered information will be put into the new variable get_scholar_id_fix. 

compsc_df$gs_id <- ""

for (i in 1:nrow(compsc_df)) {
  print(i)
  time <- runif(1, 0, 1)
  Sys.sleep(time)
  
  tryCatch({
     compsc_df[i,c("gs_id")] <- get_scholar_id_fix(last_name = compsc_df[i, c("last_name")], 
                                             first_name = compsc_df[i, c("first_name")],  
                                             affiliation = compsc_df[i,c("affiliation")]) 
    }, error=function(e){cat("ERROR :", conditionMessage(e), "\n")}) 
  }


# remove those without pubs from the df
# seems we're left with about computing science staff members!
compsc_df <- compsc_df[!compsc_df$gs_id == "", ]
compsc_df
```







```{r}
soc_list_profiles <- list()  # first we create an empty list that we then fill up with the for loop
soc_list_publications <- list()

for (i in 1:nrow(soc_df)) {
    print(i)
    time <- runif(1, 0, 1)
    Sys.sleep(time)

    # note how you call different elements in a list '[[]]', fill in the i-th element
    soc_list_profiles[[i]] <- get_profile(soc_df[i, c("gs_id")])  # Note how we call row i (remember how to call rows in a DF/Matrix) and then the associated scholar id
    soc_list_publications[[i]] <- get_publications(soc_df[i, c("gs_id")])
    soc_list_publications[[i]][, c("gs_id")] <- soc_df[i, c("gs_id")]  # note that we again attach an id
    # so both functions here call the entire profile and pubs for an author, based on google
    # scholar ids

}
# Notice how fast the data blow up! The 34 RU sociology scholars publish ~3000 papers
soc_df_publications <- bind_rows(soc_list_publications)
```


```{r}
soc_profiles_df <- list()
for (i in 1:length(soc_list_profiles)) {
    # soc_profiles_df[[i]] <- data.frame(t(unlist(soc_list_profiles[[i]][1:8]))) #some annyoing
    # data handling
    soc_profiles_df[[i]] <- unlist(soc_list_profiles[[i]][1:8])
    soc_profiles_df[[i]] <- data.frame(soc_profiles_df[[i]])
    soc_profiles_df[[i]] <- data.frame(t(soc_profiles_df[[i]]))

}
soc_profiles_df <- bind_rows(soc_profiles_df)
soc_df <- left_join(soc_df, soc_profiles_df, by = c(gs_id = "id"))  # merge data with soc_df
soc_df  # notice all the new information we were able to get from the scholar profiles!
```

```{r}
# get citation history of a scholar
soc_staff_cit <- list()
for (i in 1:nrow(soc_df)) {

    soc_staff_cit[[i]] <- get_citation_history(soc_df[i, c("gs_id")])

    if (nrow(soc_staff_cit[[i]]) > 0) {
        soc_staff_cit[[i]][, c("gs_id")] <- soc_df[i, c("gs_id")]  # again attach the gs_id as third column
    }
}
soc_staff_cit <- bind_rows(soc_staff_cit)
colnames(soc_staff_cit)[3] <- "gs_id"
```

<br>

## Getting collaborators

```{r}
require(xml2)
require(tidyverse)

# function to get collaborators and names from GS profiles
fcollabs <- function(gsid, lookforcollabs) {

  htmlpage1 <- read_html(paste0("https://scholar.google.nl/citations?user=", gsid, "&hl=en")) # so we paste the google scholar id
  profilename <- htmlpage1 %>% html_nodes(xpath = "//*/div[@id='gsc_prf_in']") %>% html_text() # we extract the profile name of that google scholar page
  profilecollabs1 <- as.data.frame(0) # empty df necessary for later
  profilecollabs2 <- as.data.frame(0) # empty df necessary for later

  if (lookforcollabs == 1) { # so if you want to look for collabs, set function to 1

    htmlpage2 <- read_html(paste0("https://scholar.google.com/citations?view_op=list_colleagues&hl=en&user=", gsid)) # so we paste the google scholar id
    profilecollabs1 <-  htmlpage2 %>% html_nodes(css="h3") %>% html_text() # get names
    profilecollabs1 <-  as.data.frame(profilecollabs1)

    profilecollabs2 <- htmlpage2 %>% html_nodes("a") %>% html_attr("href") # get the link
    profilecollabs2 <- profilecollabs2[seq_along(profilecollabs2) %% 2 > 0]
    profilecollabs2 <- substring(profilecollabs2, 23)

  }
  if (nrow(profilecollabs1)>1) { # if there ARE collabs

    profilecollabs1 <- as.data.frame(profilecollabs1) # we want to...
    profilecollabs2 <-  as.data.frame(profilecollabs2)
    profilecollabs1[,c("coauth_id")] <- profilecollabs2[,1]

    profilecollabs1[,c("gs_id")] <- gsid #... add gs_ids of focal GS profile
    profilecollabs1[,c("name")] <- profilename #...and the the profile name of GS profile attached

    names(profilecollabs1)[1] <- "coauth"

  } else {
    profilecollabs1 <- as.data.frame(cbind(gsid, profilename)) # if NOT looking for collabs...
    names(profilecollabs1) <- c("gs_id", "name") #...we only attach gs_id and profilename

  }
  return(profilecollabs1)

}

```

```{r}
# first the soc collaborators note how we already build a function (fcollabs()) for you you need to
# input a google scholar id and a 1 (if you want to find collabs) or 0 (only extracting names)
# fcollabs --> you can check it out if you're interested
soc_collabs <- list()
for (i in 1:nrow(soc_df)) {

    time <- runif(1, 0, 5)
    Sys.sleep(time)

    soc_collabs[[i]] <- fcollabs(soc_df[i, c("gs_id")], 1)

}
soc_collabs <- bind_rows(soc_collabs)  # bind rows, get the unique ones!
soc_collabs_unique <- unique(soc_collabs[, 3])  # so 229 unique collaborators for RU staff?
soc_collabs_unique <- soc_collabs_unique[!is.na(soc_collabs_unique)]
save(soc_collabs, file = "soc_df_collabs1.RData")  # you notice this takes a while, so we save the data here.
```

```{r}
# then the names of those collaborators plus THEIR collaborators understand that we don't have
# names of them yet from the code above?
collabs_1deep <- list()
for (i in 1:length(soc_collabs_unique)) {

    time <- runif(1, 0, 3)
    Sys.sleep(time)

    if (!soc_collabs_unique[i] %in% soc_df$gs_id) {
        collabs_1deep[[i]] <- fcollabs(soc_collabs_unique[i], 1)

    }
}
collabs_1deep <- bind_rows(collabs_1deep)
collabs_1deep_unique <- unique(collabs_1deep[, 2])
collabs_1deep_unique <- collabs_1deep_unique[!is.na(collabs_1deep_unique)]
save(collabs_1deep, file = "soc_collabs2.RData")  # you notice this takes a while, so we save the data here.
```

```{r}
for (i in c("_ukytQYAAAAJ", "lkVq32sAAAAJ", "p3IwtT4AAAAJ")) {
    # drop google scholar ids that look suspiciously productive
    soc_df <- soc_df[!soc_df$gs_id == i, ]
    soc_df_publications <- soc_df_publications[!(soc_df_publications$gs_id == i), ]
    soc_staff_cit <- soc_staff_cit[!(soc_staff_cit$gs_id == i), ]
    soc_collabs <- soc_collabs[!(soc_collabs$gs_id == i), ]
}
```

<br>

## Data exploration



# Webscraping the staff of the Instititute for Computing and Information Science

<br>

## Staging my script

```{r}
#start with clean workspace 
rm(list=ls())

# install.packages("data.table") 
library(data.table) # mainly for faster data handling
library(tidyverse) # I assume you already installed this one!
# install.packages("httr") # we don't need this for now
# require(httr)
# install.packages("xml2")
require(xml2)
# install.packages("rvest")
require(rvest)
# install.packages("devtools")
require(devtools)
# Note we're doing something different here. We're installing a *latest* version directly from GitHub
# This is because the released version of this packages contains some errors!
devtools::install_github("jkeirstead/scholar") 


require(scholar)

#define workdirectory, note the double *backslashes* if you're on windows
# setwd("/yourpathhere)"
```

<br>

## Getting “anchor” data 
```{r}
# Let's first get the staff page read_html is a function that simply extracts html webpages and
# puts them in xml format

# Bas --> note how i changed the link, the other link needed cookie consent (at least at my mac, so that made it complicated)
#  I followed the link on the website that just provided the lsit
comp_staff <- read_html("https://www.cs.ru.nl/staff/index.html?")

head(comp_staff)

class(comp_staff)
```
```{r}

# Individual scholars are mentioned at "a" elements of the html
comp_staff <- comp_staff %>%
    rvest::html_nodes("body") %>%
    xml2::xml_find_all("//a") %>% 
    rvest::html_text()
  
comp_staff

```


```{r}
# Making a dataframe of comp_staff, called comp_df
comp_df <- data.frame(comp_staff)

print(comp_df)

```


```{r}
# Removing all individual letters of the alphabet.
delrows <- which(comp_df$comp_staff == "A" | comp_df$comp_staff == "B" | comp_df$comp_staff == "C" | comp_df$comp_staff == "D" | comp_df$comp_staff == "E" | comp_df$comp_staff == "F" |  comp_df$comp_staff == "G" | comp_df$comp_staff == "H" | comp_df$comp_staff == "I" | comp_df$comp_staff == "J" | comp_df$comp_staff == "K" | comp_df$comp_staff == "L" | comp_df$comp_staff == "M" | comp_df$comp_staff == "N" | comp_df$comp_staff == "O" | comp_df$comp_staff == "P" | comp_df$comp_staff == "Q" | comp_df$comp_staff == "R" | comp_df$comp_staff == "S" | comp_df$comp_staff == "T" | comp_df$comp_staff == "U" | comp_df$comp_staff == "V" | comp_df$comp_staff == "W" | comp_df$comp_staff == "X" | comp_df$comp_staff == "Y" | comp_df$comp_staff == "Z")

comp_df <- comp_df[-delrows, ]
```


-------

```{r}
# Making a dataframe of comp_df, called compsc_df
compsc_df <- data.frame(comp_df)

# Giving the first (and only column) of comp_df the name 'comp_names'
colnames(compsc_df)[colnames(compsc_df) == "comp_df"] <- "comp_names"

colnames(compsc_df)

```
```{r}
# Creating a new variable with the titles of the respondents
compsc_df$title <- gsub(" .*", "", compsc_df$comp_names)

# Creating a new variable with the last names of the respondents
compsc_df$last_name <- gsub('^.* ([[:alnum:]]+)$', '\\1', compsc_df$comp_names)

# Creating a new variable with the first names of the respondents
compsc_df$first_name <- str_extract_all(compsc_df$comp_names, "(?<=\\().+?(?=\\))", simplify = TRUE)

```

```{r}
# !!! Trying to change the mistakes in the coding of the last names
compsc_df$last_name <- gsub('MSc S.\\(Saeid\\)', '', compsc_df$comp_names)


# Turning all letters into lowercase letters
compsc_df$first_name <- tolower(compsc_df$first_name)  # everything to lower!
compsc_df$last_name <- tolower(compsc_df$last_name)
```

```{r}
# trimws looses all spacing before and after (if you specify 'both') a character string
compsc_df$last_name <- trimws(compsc_df$last_name, which = c("both"), whitespace = "[ \t\r\n]")

compsc_df$first_name <- trimws(compsc_df$first_name, which = c("both"), whitespace = "[ \t\r\n]")

compsc_df$comp_names <- trimws(compsc_df$comp_names, which = c("both"), whitespace = "[ \t\r\n]")
```

```{r}
# setting an affiliation to Radboud University
compsc_df$affiliation <- "radboud university"
```

```{r}
compsc_df
```

```{r}
# Setting an empty identifier
compsc_df$gs_id <- ""  
```

```{r}
#require(scholar)

get_scholar_id_fix <- function (last_name = "", first_name = "", affiliation = NA)
{
  if (!any(nzchar(c(first_name, last_name))))
    stop("At least one of first and last name must be specified!")
  site <- getOption("scholar_site")
  url <- paste0(site, "/citations?view_op=search_authors&mauthors=",
                first_name, "+", last_name, "&hl=en&oi=ao")
  page <- get_scholar_resp(url)
  if (is.null(page))
    return(NA)
  aa <- httr::content(page, as = "text")
  # added by Bas Hofstra: bugfix for IDs that have a dash ("-")
  ids <- substring(aa, regexpr(";user=", aa))
  ids <- substr(ids, 1, 19) # error prone, but unsure how to solve otherwise
  # if (nchar(stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]")[[1]][1]) < 18) {
  #   ids <- stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]+[[:alnum:]]+[[:punct:]]")
  # } else {
  #   ids <- stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]")
  # }
  if (length(unlist(ids)) == 0) {
    message("No Scholar ID found.")
    return(NA)
  }
  ids <- ids %>% unlist %>% gsub(";user=|[[:punct:]]$", "",
                                 .) %>% unique
  if (length(ids) > 1) {
    profiles <- lapply(ids, scholar::get_profile)
    if (is.na(affiliation)) {
      x_profile <- profiles[[1]]
      warning("Selecting first out of ", length(profiles),
              " candidate matches.")
    }
    else {
      which_profile <- sapply(profiles, function(x) {
        stringr::str_count(string = x$affiliation, pattern = stringr::coll(affiliation,
                                                                           ignore_case = TRUE))
      })
      if (all(which_profile == 0)) {
        warning("No researcher found at the indicated affiliation.")
        return(NA)
      }
      else {
        x_profile <- profiles[[which(which_profile !=
                                       0)]]
      }
    }
  }
  else {
    x_profile <- scholar::get_profile(id = ids)
  }
  return(x_profile$id)
}
```






```{r}
# Getting the google scholar id of all the computing science staff members (by using the following variables: last_name, first_name, affiliation). The gathered information will be put into the new variable get_scholar_id_fix. 

compsc_df$gs_id <- ""

for (i in 1:nrow(compsc_df)) {
  print(i)
  time <- runif(1, 0, 1)
  Sys.sleep(time)
  
  tryCatch({
     compsc_df[i,c("gs_id")] <- get_scholar_id_fix(last_name = compsc_df[i, c("last_name")], 
                                             first_name = compsc_df[i, c("first_name")],  
                                             affiliation = compsc_df[i,c("affiliation")]) 
    }, error=function(e){cat("ERROR :", conditionMessage(e), "\n")}) 
  }


# remove those without pubs from the df
# seems we're left with about computing science staff members!
# compsc_df <- compsc_df[!compsc_df$gs_id == "", ]
compsc_df
```







```{r}
soc_list_profiles <- list()  # first we create an empty list that we then fill up with the for loop
soc_list_publications <- list()

for (i in 1:nrow(soc_df)) {
    print(i)
    time <- runif(1, 0, 1)
    Sys.sleep(time)

    # note how you call different elements in a list '[[]]', fill in the i-th element
    soc_list_profiles[[i]] <- get_profile(soc_df[i, c("gs_id")])  # Note how we call row i (remember how to call rows in a DF/Matrix) and then the associated scholar id
    soc_list_publications[[i]] <- get_publications(soc_df[i, c("gs_id")])
    soc_list_publications[[i]][, c("gs_id")] <- soc_df[i, c("gs_id")]  # note that we again attach an id
    # so both functions here call the entire profile and pubs for an author, based on google
    # scholar ids

}
# Notice how fast the data blow up! The 34 RU sociology scholars publish ~3000 papers
soc_df_publications <- bind_rows(soc_list_publications)
```


```{r}
soc_profiles_df <- list()
for (i in 1:length(soc_list_profiles)) {
    # soc_profiles_df[[i]] <- data.frame(t(unlist(soc_list_profiles[[i]][1:8]))) #some annyoing
    # data handling
    soc_profiles_df[[i]] <- unlist(soc_list_profiles[[i]][1:8])
    soc_profiles_df[[i]] <- data.frame(soc_profiles_df[[i]])
    soc_profiles_df[[i]] <- data.frame(t(soc_profiles_df[[i]]))

}
soc_profiles_df <- bind_rows(soc_profiles_df)
soc_df <- left_join(soc_df, soc_profiles_df, by = c(gs_id = "id"))  # merge data with soc_df
soc_df  # notice all the new information we were able to get from the scholar profiles!
```

```{r}
# get citation history of a scholar
soc_staff_cit <- list()
for (i in 1:nrow(soc_df)) {

    soc_staff_cit[[i]] <- get_citation_history(soc_df[i, c("gs_id")])

    if (nrow(soc_staff_cit[[i]]) > 0) {
        soc_staff_cit[[i]][, c("gs_id")] <- soc_df[i, c("gs_id")]  # again attach the gs_id as third column
    }
}
soc_staff_cit <- bind_rows(soc_staff_cit)
colnames(soc_staff_cit)[3] <- "gs_id"
```

<br>

## Getting collaborators

```{r}
require(xml2)
require(tidyverse)

# function to get collaborators and names from GS profiles
fcollabs <- function(gsid, lookforcollabs) {

  htmlpage1 <- read_html(paste0("https://scholar.google.nl/citations?user=", gsid, "&hl=en")) # so we paste the google scholar id
  profilename <- htmlpage1 %>% html_nodes(xpath = "//*/div[@id='gsc_prf_in']") %>% html_text() # we extract the profile name of that google scholar page
  profilecollabs1 <- as.data.frame(0) # empty df necessary for later
  profilecollabs2 <- as.data.frame(0) # empty df necessary for later

  if (lookforcollabs == 1) { # so if you want to look for collabs, set function to 1

    htmlpage2 <- read_html(paste0("https://scholar.google.com/citations?view_op=list_colleagues&hl=en&user=", gsid)) # so we paste the google scholar id
    profilecollabs1 <-  htmlpage2 %>% html_nodes(css="h3") %>% html_text() # get names
    profilecollabs1 <-  as.data.frame(profilecollabs1)

    profilecollabs2 <- htmlpage2 %>% html_nodes("a") %>% html_attr("href") # get the link
    profilecollabs2 <- profilecollabs2[seq_along(profilecollabs2) %% 2 > 0]
    profilecollabs2 <- substring(profilecollabs2, 23)

  }
  if (nrow(profilecollabs1)>1) { # if there ARE collabs

    profilecollabs1 <- as.data.frame(profilecollabs1) # we want to...
    profilecollabs2 <-  as.data.frame(profilecollabs2)
    profilecollabs1[,c("coauth_id")] <- profilecollabs2[,1]

    profilecollabs1[,c("gs_id")] <- gsid #... add gs_ids of focal GS profile
    profilecollabs1[,c("name")] <- profilename #...and the the profile name of GS profile attached

    names(profilecollabs1)[1] <- "coauth"

  } else {
    profilecollabs1 <- as.data.frame(cbind(gsid, profilename)) # if NOT looking for collabs...
    names(profilecollabs1) <- c("gs_id", "name") #...we only attach gs_id and profilename

  }
  return(profilecollabs1)

}

```

```{r}
# first the soc collaborators note how we already build a function (fcollabs()) for you you need to
# input a google scholar id and a 1 (if you want to find collabs) or 0 (only extracting names)
# fcollabs --> you can check it out if you're interested
soc_collabs <- list()
for (i in 1:nrow(soc_df)) {

    time <- runif(1, 0, 5)
    Sys.sleep(time)

    soc_collabs[[i]] <- fcollabs(soc_df[i, c("gs_id")], 1)

}
soc_collabs <- bind_rows(soc_collabs)  # bind rows, get the unique ones!
soc_collabs_unique <- unique(soc_collabs[, 3])  # so 229 unique collaborators for RU staff?
soc_collabs_unique <- soc_collabs_unique[!is.na(soc_collabs_unique)]
save(soc_collabs, file = "soc_df_collabs1.RData")  # you notice this takes a while, so we save the data here.
```

```{r}
# then the names of those collaborators plus THEIR collaborators understand that we don't have
# names of them yet from the code above?
collabs_1deep <- list()
for (i in 1:length(soc_collabs_unique)) {

    time <- runif(1, 0, 3)
    Sys.sleep(time)

    if (!soc_collabs_unique[i] %in% soc_df$gs_id) {
        collabs_1deep[[i]] <- fcollabs(soc_collabs_unique[i], 1)

    }
}
collabs_1deep <- bind_rows(collabs_1deep)
collabs_1deep_unique <- unique(collabs_1deep[, 2])
collabs_1deep_unique <- collabs_1deep_unique[!is.na(collabs_1deep_unique)]
save(collabs_1deep, file = "soc_collabs2.RData")  # you notice this takes a while, so we save the data here.
```

```{r}
for (i in c("_ukytQYAAAAJ", "lkVq32sAAAAJ", "p3IwtT4AAAAJ")) {
    # drop google scholar ids that look suspiciously productive
    soc_df <- soc_df[!soc_df$gs_id == i, ]
    soc_df_publications <- soc_df_publications[!(soc_df_publications$gs_id == i), ]
    soc_staff_cit <- soc_staff_cit[!(soc_staff_cit$gs_id == i), ]
    soc_collabs <- soc_collabs[!(soc_collabs$gs_id == i), ]
}
```

<br>

## Data exploration



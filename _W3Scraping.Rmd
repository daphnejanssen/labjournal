
---
title: "Journal 3"
#bibliography: references.bib
author: "Daphne Janssen"
---



```{r, globalsettings, echo=FALSE, warning=FALSE, results='hide'}
library(knitr)

knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=100),tidy=TRUE, warning = FALSE, message = FALSE,comment = "#>", cache=TRUE, class.source=c("test"), class.output=c("test2"))
options(width = 100)
rgl::setupKnitr()



colorize <- function(x, color) {sprintf("<span style='color: %s;'>%s</span>", color, x) }

```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy(position = c('top', 'right'))
#klippy::klippy(color = 'darkred')
#klippy::klippy(tooltip_message = 'Click to copy', tooltip_success = 'Done')
```

Last compiled on `r Sys.time()`

<!---
Last compiled on `r format(Sys.time(), '%B, %Y')`
--->


<br>

----

---

# Webscraping

```{r}
######################################### Title: Webscraping in R Author: Bas Hofstra Version:
######################################### 29-07-2021

# start with clean workspace
rm(list = ls())

# install.packages('data.table')
library(data.table)  # mainly for faster data handling
library(tidyverse)  # I assume you already installed this one!
# install.packages('httr') # we don't need this for now require(httr)
install.packages("xml2")
require(xml2)
install.packages("rvest")
require(rvest)
install.packages("devtools")
require(devtools)
# Note we're doing something different here. We're installing a *latest* version directly from
# GitHub This is because the released version of this packages contains some errors!
devtools::install_github("jkeirstead/scholar")

require(scholar)

# define workdirectory, note the double *backslashes* if you're on windows setwd('/yourpathhere)'
```

```{r}
rm(list = ls())
# Let's first get the staff page read_html is a function that simply extracts html webpages and
# puts them in xml format
soc_staff <- read_html("https://www.ru.nl/sociology/research/staff/")

head(soc_staff)

class(soc_staff)
```
```{r}
# so we need to find WHERE the table is located in the html 'inspect element' in mozilla firefox or
# 'view page source' and you see that everything AFTER /td in the 'body' of the page seems to be
# the table we do need
soc_staff <- soc_staff %>%
    rvest::html_nodes("body") %>%
    xml2::xml_find_all("//td") %>%
    rvest::html_text()
```

our own code works, but let us use the code in SNASS
```{r}
#seq(from=1, to=length(soc_staff), by=2)

#soc_staff <- soc_staff[seq(from=1, to=length(soc_staff), by=2)]

#soc_staff
```

```{r}
fodd <- function(x) {
  #what is x, x is a vector
  x%%2 != 0
}

feven <- function(x) x%%2 == 0

nstaff <- length(soc_staff)
#nstaff
#fodd(1:nstaff)

# Do you understand why we need the nstaff? What it does?
soc_names <- soc_staff[fodd(1:nstaff)]  # in the 1 until 94st number, get the odd elements
head(soc_names)
```

```{r}
soc_experts <- soc_staff[feven(1:nstaff)]  # in the 1 until 94st number, get the even elements
head(soc_experts)
```

```{r}
soc_df <- data.frame(cbind(soc_names, soc_experts))  # columnbind those and we have a DF for soc staff!
```

```{r}
soc_df  # pretty nice!
```
```{r}
# inspect again, and remove the rows we don't need (check for yourself to be certain!)

delrows <- which(soc_df$soc_names == "Staff:" | soc_df$soc_names == "PhD:" | soc_df$soc_names == "External PhD:" |
    soc_df$soc_names == "Guest researchers:" | soc_df$soc_names == "Other researchers:")

soc_df <- soc_df[-delrows, ]
```

```{r}
soc_df  # even better
```

```{r}
# Last name seems to be everything before the comma
soc_df$last_name <- gsub(",.*$", "", soc_df$soc_names)

# first name is everything between brackets
soc_df$first_name <- str_extract_all(soc_df$soc_names, "(?<=\\().+?(?=\\))", simplify = TRUE)

soc_df
```

```{r}
soc_df$last_name <- gsub(" J. \\(Jansje\\) van MSc", "", soc_df$last_name)
soc_df$first_name <- tolower(soc_df$first_name)  # everything to lower!
soc_df$last_name <- tolower(soc_df$last_name)
```

```{r}
# trimws looses all spacing before and after (if you specify 'both') a character string
soc_df$last_name <- trimws(soc_df$last_name, which = c("both"), whitespace = "[ \t\r\n]")
soc_df$first_name <- trimws(soc_df$first_name, which = c("both"), whitespace = "[ \t\r\n]")
soc_df$soc_experts <- trimws(soc_df$soc_experts, which = c("both"), whitespace = "[ \t\r\n]")
soc_df$soc_names <- trimws(soc_df$soc_names, which = c("both"), whitespace = "[ \t\r\n]")
```

```{r}
# set affiliation to radboud, comes in handy for querying google scholar
soc_df$affiliation <- "radboud university"

soc_df
```


```{r}
soc_df$gs_id <- ""  # we set an empty identifier
```


```{r}
require(scholar)

get_scholar_id_fix <- function (last_name = "", first_name = "", affiliation = NA)
{
  if (!any(nzchar(c(first_name, last_name))))
    stop("At least one of first and last name must be specified!")
  site <- getOption("scholar_site")
  url <- paste0(site, "/citations?view_op=search_authors&mauthors=",
                first_name, "+", last_name, "&hl=en&oi=ao")
  page <- get_scholar_resp(url)
  if (is.null(page))
    return(NA)
  aa <- httr::content(page, as = "text")
  # added by Bas Hofstra: bugfix for IDs that have a dash ("-")
  ids <- substring(aa, regexpr(";user=", aa))
  ids <- substr(ids, 1, 19) # error prone, but unsure how to solve otherwise
  # if (nchar(stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]")[[1]][1]) < 18) {
  #   ids <- stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]+[[:alnum:]]+[[:punct:]]")
  # } else {
  #   ids <- stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]")
  # }
  if (length(unlist(ids)) == 0) {
    message("No Scholar ID found.")
    return(NA)
  }
  ids <- ids %>% unlist %>% gsub(";user=|[[:punct:]]$", "",
                                 .) %>% unique
  if (length(ids) > 1) {
    profiles <- lapply(ids, scholar::get_profile)
    if (is.na(affiliation)) {
      x_profile <- profiles[[1]]
      warning("Selecting first out of ", length(profiles),
              " candidate matches.")
    }
    else {
      which_profile <- sapply(profiles, function(x) {
        stringr::str_count(string = x$affiliation, pattern = stringr::coll(affiliation,
                                                                           ignore_case = TRUE))
      })
      if (all(which_profile == 0)) {
        warning("No researcher found at the indicated affiliation.")
        return(NA)
      }
      else {
        x_profile <- profiles[[which(which_profile !=
                                       0)]]
      }
    }
  }
  else {
    x_profile <- scholar::get_profile(id = ids)
  }
  return(x_profile$id)
}
```

```{r}
#source("addfiles/function_fix.R")  # Put the function_fix.R in your working directory, we need this first line.

get_scholar_id_fix(last_name = "tolsma", first_name = "jochem", affiliation = "radboud university")
```
```{r}
get_profile("Iu23-90AAAAJ")  # Jochem's profile
```

```{r}
get_publications("Iu23-90AAAAJ")  # Jochem's pubs
```
```{r}
get_citation_history("Iu23-90AAAAJ")  # Jochem's citation history
```
```{r}
jochem_coauthors <- get_coauthors("Iu23-90AAAAJ", n_coauthors = 50, n_deep = 1)  # Jochem's collaborators and their co-authors!

jochem_coauthors
```

```{r}
plot_coauthors(get_coauthors("Iu23-90AAAAJ", n_coauthors = 20, n_deep = 1), size_labels = 2)  # Doesn't look like much yet, but we'll make it prettier later.
```


```{r}

nrow (soc_df)

#save data in some object.
soc_df$si <- NA

#Create the loop with nrow(soc_df) indicating the number of rows (46), saving the google scholar id's in the variable si in the dataset soc_df. 
for (i in 1:nrow(soc_df)) {
  soc_df$si[i] <- get_scholar_id_fix(
    last_name = soc_df$last_name[i], 
    first_name = soc_df$first_name[i], 
    affiliation = soc_df$affiliation[i])
}

soc_df
```
```{r}
# Look throught get_scholar_id_fix(last_name, first_name, affiliation) 
# if we can find google scholar profiles of sociology staff!
for (i in 1:nrow(soc_df)) {
  
  time <- runif(1, 0, 5)
  Sys.sleep(time)
  
  tryCatch({
     soc_df[i,c("gs_id")] <- get_scholar_id_fix(last_name = soc_df[i, c("last_name")], # so search on last_name of staff (third column)
                                             first_name = soc_df[i, c("first_name")],  # search on first_name of staff (fourth column)
                                             affiliation = soc_df[i,c("affiliation")]) # search on affiliation of each staff (fifth column)

    }, error=function(e){cat("ERROR :", conditionMessage(e), "\n")}) # continue on error, but print the error
  }

# remove those without pubs from the df
# seems we're left with about 34 sociology staff members!
soc_df <- soc_df[!soc_df$gs_id == "", ]

# You dont have to delete on emopty ideas, but you need to specify. 
soc_df <- soc_df[!is.na(soc_df$gs_id),]
```


